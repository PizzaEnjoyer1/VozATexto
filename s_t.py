import os
import streamlit as st
from bokeh.models.widgets import Button
from bokeh.models import CustomJS
from streamlit_bokeh_events import streamlit_bokeh_events
from PIL import Image
import time
import glob
from gtts import gTTS
from googletrans import Translator
import base64

st.title("TRADUCTOR.")
st.subheader("Escucho lo que quieres traducir.")

image = Image.open('OIG7.jpg')
st.image(image, width=300)

with st.sidebar:
    st.subheader("Traductor.")
    st.write("Presiona el bot√≥n, cuando escuches la se√±al "
             "habla lo que quieres traducir, luego selecciona"
             " la configuraci√≥n de lenguaje que necesites.")

st.write("Toca el Bot√≥n y habla lo que quieres traducir")

stt_button = Button(label=" Escuchar  üé§ (Solo presiona una vez y luego habla)", width=300, height=50)

stt_button.js_on_event("button_click", CustomJS(code=""" 
    var recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = function (e) {
        var value = "";
        for (var i = e.resultIndex; i < e.results.length; ++i) {
            if (e.results[i].isFinal) {
                value += e.results[i][0].transcript;
            }
        }
        if (value != "") {
            document.dispatchEvent(new CustomEvent("GET_TEXT", {detail: value}));
        }
    }
    recognition.start();
"""))

result = streamlit_bokeh_events(
    stt_button,
    events="GET_TEXT",
    key="listen",
    refresh_on_update=False,
    override_height=75,
    debounce_time=0)

if result:
    if "GET_TEXT" in result:
        captured_text = result.get("GET_TEXT")
        st.write(captured_text)

        # Detecci√≥n de idioma
        detected_language = Translator().detect(captured_text).lang
        language_names = {
            "en": "Ingl√©s",
            "es": "Espa√±ol",
            "bn": "Bengal√≠",
            "ko": "Coreano",
            "zh-cn": "Mandar√≠n",
            "ja": "Japon√©s",
            "fr": "Franc√©s",
            "de": "Alem√°n",
            "pt": "Portugu√©s",
            "ru": "Ruso"
        }
        st.markdown(f"**El idioma que hablaste fue: {language_names.get(detected_language, 'Desconocido')}**")

    try:
        os.mkdir("temp")
    except:
        pass

    st.title("Texto a Audio")
    translator = Translator()

    text = str(captured_text)
    language_options = [
        "Ingl√©s", "Espa√±ol", "Bengal√≠", "Coreano", "Mandar√≠n",
        "Japon√©s", "Franc√©s", "Alem√°n", "Portugu√©s", "Ruso"
    ]
    
    in_lang = st.selectbox("Selecciona el lenguaje de Entrada", language_options)
    out_lang = st.selectbox("Selecciona el lenguaje de salida", language_options)

    language_codes = {
        "Ingl√©s": "en",
        "Espa√±ol": "es",
        "Bengal√≠": "bn",
        "Coreano": "ko",
        "Mandar√≠n": "zh-cn",
        "Japon√©s": "ja",
        "Franc√©s": "fr",
        "Alem√°n": "de",
        "Portugu√©s": "pt",
        "Ruso": "ru"
    }

    input_language = language_codes[in_lang]
    output_language = language_codes[out_lang]

    english_accent = st.selectbox(
        "Selecciona el acento",
        (
            "Defecto",
            "Espa√±ol",
            "Reino Unido",
            "Estados Unidos",
            "Canada",
            "Australia",
            "Irlanda",
            "Sud√°frica",
        ),
    )

    if english_accent == "Defecto":
        tld = "com"
    elif english_accent == "Espa√±ol":
        tld = "com.mx"
    elif english_accent == "Reino Unido":
        tld = "co.uk"
    elif english_accent == "Estados Unidos":
        tld = "com"
    elif english_accent == "Canada":
        tld = "ca"
    elif english_accent == "Australia":
        tld = "com.au"
    elif english_accent == "Irlanda":
        tld = "ie"
    elif english_accent == "Sud√°frica":
        tld = "co.za"

    # Funci√≥n de conversi√≥n de texto a voz
    def text_to_speech(input_language, output_language, text, tld):
        translation = translator.translate(text, src=input_language, dest=output_language)
        trans_text = translation.text
        tts = gTTS(trans_text, lang=output_language, tld=tld, slow=False)
        try:
            my_file_name = text[0:20]
        except:
            my_file_name = "audio"
        tts.save(f"temp/{my_file_name}.mp3")
        return my_file_name, trans_text

    display_output_text = st.checkbox("Mostrar el texto")

    # Mostrar GIF de carga mientras se procesa el audio
    loading_gif = 'assets/loading.gif'  # Ruta al GIF de carga

    if st.button("Convertir"):
        gif_placeholder = st.empty()

        # Mostrar GIF de carga
        with gif_placeholder:
            st.markdown(
                f'<img src="data:image/gif;base64,{base64.b64encode(open(loading_gif, "rb").read()).decode()}" width="100" alt="Loading...">',
                unsafe_allow_html=True
            )

        # Simular tiempo de procesamiento
        time.sleep(2)

        # Generar audio y texto traducido
        result, output_text = text_to_speech(input_language, output_language, text, tld)

        # Detener el GIF de carga
        gif_placeholder.empty()

        # Reproducir audio generado
        audio_file = open(f"temp/{result}.mp3", "rb")
        audio_bytes = audio_file.read()
        st.markdown(f"## Tu audio:")
        st.audio(audio_bytes, format="audio/mp3", start_time=0)

        # Mostrar texto traducido si se selecciona
        if display_output_text:
            st.markdown(f"## Texto de salida:")
            st.write(f"{output_text}")

    # Funci√≥n para eliminar archivos antiguos
    def remove_files(n):
        mp3_files = glob.glob("temp/*mp3")
        if len(mp3_files) != 0:
            now = time.time()
            n_days = n * 86400
            for f in mp3_files:
                if os.stat(f).st_mtime < now - n_days:
                    os.remove(f)
                    print("Deleted ", f)

    remove_files(7)
